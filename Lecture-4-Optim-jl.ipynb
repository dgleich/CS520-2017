{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Plots\n",
    "using Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition f(Any) in module Main at In[5]:3 overwritten at In[6]:3.\n",
      "WARNING: Method definition g!(Array{T<:Any, 1}, Array{T<:Any, 1}) in module Main at In[5]:6 overwritten at In[6]:6.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Results of Optimization Algorithm\n",
       " * Algorithm: Gradient Descent\n",
       " * Starting Point: [0.0,0.0]\n",
       " * Minimizer: [0.9356732500354086,0.875073922357589]\n",
       " * Minimum: 0.004155\n",
       " * Iterations: 1000\n",
       " * Convergence: false\n",
       "   * |x - x'| < 1.0e-32: false\n",
       "   * |f(x) - f(x')| / |f(x)| < 1.0e-08: false\n",
       "   * |g(x)| < 1.0e-08: false\n",
       "   * Reached Maximum Number of Iterations: true\n",
       " * Objective Function Calls: 3532\n",
       " * Gradient Calls: 3532"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of Rosenbrock function\n",
    "function f(x) \n",
    "    return (1.0 - x[1])^2 + 100.0 * (x[2] - x[1]^2)^2\n",
    "end\n",
    "function g!(x::Vector, storage::Vector)\n",
    "storage[1] = -2.0 * (1.0 - x[1]) - 400.0 * (x[2] - x[1]^2) * x[1]\n",
    "storage[2] = 200.0 * (x[2] - x[1]^2)\n",
    "end\n",
    "\n",
    "soln = optimize(f, g!, [0.0, 0.0], GradientDescent())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15Ã—1 Array{Float64,2}:\n",
       " -0.961733 \n",
       "  0.256498 \n",
       "  1.35844  \n",
       "  0.176834 \n",
       "  0.0325291\n",
       " -0.494308 \n",
       " -1.62881  \n",
       "  0.586711 \n",
       "  1.18127  \n",
       "  2.75914  \n",
       "  0.697867 \n",
       " -0.408102 \n",
       " -0.121016 \n",
       "  0.498591 \n",
       " -0.511114 "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshape(randn(5,3),15,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix_approx_gradient! (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now, we do the matrix factorization example\n",
    "# originally from Poblano example2\n",
    "\n",
    "function matrix_approx_function(x::Vector, A::Matrix, r::Int)\n",
    "    # unpack U and V from x\n",
    "    m,n = size(A)\n",
    "    U = reshape(x[1:m*r],m,r)\n",
    "    V = reshape(x[(m*r+1):end],n,r)\n",
    "    return 0.5*vecnorm(A - U*V')^2\n",
    "end\n",
    "\n",
    "function matrix_approx_gradient!(x::Vector, storage::Vector, A::Matrix, r::Int)\n",
    "    m,n = size(A)\n",
    "    U = reshape(x[1:m*r],m,r)\n",
    "    V = reshape(x[(m*r+1):end],n,r)\n",
    "    D = A - U*V'\n",
    "    storage[1:(m*r)] = -vec(D*V)\n",
    "    storage[(m*r+1):end] = -vec(D'*U)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soln = Results of Optimization Algorithm\n",
      " * Algorithm: L-BFGS\n",
      " * Starting Point: [0.5076239629135827,-2.4524181370438063, ...]\n",
      " * Minimizer: [-0.28410788577451856,-0.0274782495321566, ...]\n",
      " * Minimum: 1.254834\n",
      " * Iterations: 28\n",
      " * Convergence: true\n",
      "   * |x - x'| < 1.0e-32: false\n",
      "   * |f(x) - f(x')| / |f(x)| < 1.0e-08: true\n",
      "   * |g(x)| < 1.0e-08: false\n",
      "   * Reached Maximum Number of Iterations: false\n",
      " * Objective Function Calls: 102\n",
      " * Gradient Calls: 102\n",
      "objval = 2.509668413720704\n",
      "opterr = 2.509668413720704\n",
      "svderr = 2.509668400349696\n"
     ]
    }
   ],
   "source": [
    "m = 5\n",
    "n = 4\n",
    "A = randn(m,n)\n",
    "r = 2\n",
    "myf = x -> matrix_approx_function(x, A, r)\n",
    "myg! = (x, storage) -> matrix_approx_gradient!(x, storage, A, r)\n",
    "\n",
    "#soln = optimize(myf, myg!, randn(m*r+n*r), LBFGS(), Optim.Options(f_tol = 1e-8))\n",
    "soln = optimize(myf, myg!, randn(m*r+n*r), LBFGS(), OptimizationOptions(ftol = 1e-8))\n",
    "x = Optim.minimizer(soln)\n",
    "@show soln\n",
    "Uopt = reshape(x[(1:m*r)],m,r)\n",
    "Vopt = reshape(x[(m*r+1):end],n,r)\n",
    "objval = 2*myf(x)\n",
    "opterr = vecnorm(A-Uopt*Vopt')^2\n",
    "\n",
    "Usvd,Ssvd,Vsvd = svd(A)\n",
    "svderr = vecnorm(A-Usvd[:,1:r]*diagm(Ssvd[1:r])*Vsvd[:,1:r]')^2\n",
    "@show objval\n",
    "@show opterr\n",
    "@show svderr\n",
    "; # hide final output in JuliaBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
